{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44542992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign: 1536 train | 384 val | 480 test\n",
      "Malignant: 1536 train | 384 val | 480 test\n",
      "BCC: 1536 train | 384 val | 480 test\n",
      "\n",
      "âœ… DATASET CREATED FROM SCRATCH â€” BALANCED & READY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "BASE_DIR = r\"C:\\Users\\Umair\\Desktop\\Data set isic\"\n",
    "OUT_DIR  = r\"C:\\Users\\Umair\\Desktop\\ISIC_BALANCED_FINAL\"\n",
    "\n",
    "CLASSES = [\"Benign\", \"Malignant\", \"BCC\"]\n",
    "IMG_EXTS = (\".jpg\", \".png\", \".jpeg\")\n",
    "\n",
    "TARGET_PER_CLASS = 2400  # dictated by Benign\n",
    "\n",
    "# =========================\n",
    "# CREATE OUTPUT FOLDERS\n",
    "# =========================\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in CLASSES:\n",
    "        os.makedirs(os.path.join(OUT_DIR, split, cls), exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# LOAD IMAGES\n",
    "# =========================\n",
    "def load_images(folder):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if f.lower().endswith(IMG_EXTS)\n",
    "    ]\n",
    "\n",
    "# =========================\n",
    "# PROCESS EACH CLASS\n",
    "# =========================\n",
    "for cls in CLASSES:\n",
    "    src_dir = os.path.join(BASE_DIR, cls)\n",
    "    imgs = load_images(src_dir)\n",
    "\n",
    "    if len(imgs) < TARGET_PER_CLASS:\n",
    "        raise ValueError(f\"{cls} has fewer than {TARGET_PER_CLASS} images\")\n",
    "\n",
    "    # 1ï¸âƒ£ Downsample to 2400\n",
    "    imgs = random.sample(imgs, TARGET_PER_CLASS)\n",
    "\n",
    "    # 2ï¸âƒ£ Shuffle\n",
    "    random.shuffle(imgs)\n",
    "\n",
    "    # 3ï¸âƒ£ Split\n",
    "    n_test = int(0.2 * TARGET_PER_CLASS)          # 480\n",
    "    n_train_val = TARGET_PER_CLASS - n_test       # 1920\n",
    "    n_val = int(0.2 * n_train_val)                # 384\n",
    "    n_train = n_train_val - n_val                 # 1536\n",
    "\n",
    "    test_imgs = imgs[:n_test]\n",
    "    val_imgs = imgs[n_test:n_test + n_val]\n",
    "    train_imgs = imgs[n_test + n_val:]\n",
    "\n",
    "    # 4ï¸âƒ£ Copy files\n",
    "    for src in train_imgs:\n",
    "        shutil.copy2(src, os.path.join(OUT_DIR, \"train\", cls, os.path.basename(src)))\n",
    "\n",
    "    for src in val_imgs:\n",
    "        shutil.copy2(src, os.path.join(OUT_DIR, \"val\", cls, os.path.basename(src)))\n",
    "\n",
    "    for src in test_imgs:\n",
    "        shutil.copy2(src, os.path.join(OUT_DIR, \"test\", cls, os.path.basename(src)))\n",
    "\n",
    "    print(\n",
    "        f\"{cls}: \"\n",
    "        f\"{len(train_imgs)} train | \"\n",
    "        f\"{len(val_imgs)} val | \"\n",
    "        f\"{len(test_imgs)} test\"\n",
    "    )\n",
    "\n",
    "print(\"\\nâœ… DATASET CREATED FROM SCRATCH â€” BALANCED & READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb215345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” VERIFYING DATASET STRUCTURE & COUNTS\n",
      "\n",
      "ðŸ“‚ TRAIN\n",
      "  Benign: 1536 images âœ…\n",
      "  Malignant: 1536 images âœ…\n",
      "  BCC: 1536 images âœ…\n",
      "\n",
      "ðŸ“‚ VAL\n",
      "  Benign: 384 images âœ…\n",
      "  Malignant: 384 images âœ…\n",
      "  BCC: 384 images âœ…\n",
      "\n",
      "ðŸ“‚ TEST\n",
      "  Benign: 480 images âœ…\n",
      "  Malignant: 480 images âœ…\n",
      "  BCC: 480 images âœ…\n",
      "\n",
      "ðŸ”Ž CHECKING FOR DATA LEAKAGE\n",
      "\n",
      "âœ… No overlap in Benign\n",
      "âœ… No overlap in Malignant\n",
      "âœ… No overlap in BCC\n",
      "\n",
      "==============================\n",
      "ðŸŽ‰ DATASET VERIFIED SUCCESSFULLY\n",
      "âœ” Balanced\n",
      "âœ” Correct splits\n",
      "âœ” No leakage\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\Umair\\Desktop\\ISIC_BALANCED_FINAL\"\n",
    "\n",
    "CLASSES = [\"Benign\", \"Malignant\", \"BCC\"]\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "IMG_EXTS = (\".jpg\", \".png\", \".jpeg\")\n",
    "\n",
    "EXPECTED_COUNTS = {\n",
    "    \"train\": 1536,\n",
    "    \"val\": 384,\n",
    "    \"test\": 480\n",
    "}\n",
    "\n",
    "print(\"ðŸ” VERIFYING DATASET STRUCTURE & COUNTS\\n\")\n",
    "\n",
    "all_ok = True\n",
    "split_files = {cls: {} for cls in CLASSES}\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"ðŸ“‚ {split.upper()}\")\n",
    "    for cls in CLASSES:\n",
    "        path = os.path.join(BASE_DIR, split, cls)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"âŒ Missing folder: {path}\")\n",
    "            all_ok = False\n",
    "            continue\n",
    "\n",
    "        files = [\n",
    "            f for f in os.listdir(path)\n",
    "            if f.lower().endswith(IMG_EXTS)\n",
    "        ]\n",
    "\n",
    "        split_files[cls][split] = set(files)\n",
    "\n",
    "        expected = EXPECTED_COUNTS[split]\n",
    "        actual = len(files)\n",
    "\n",
    "        status = \"âœ…\" if actual == expected else \"âŒ\"\n",
    "        if actual != expected:\n",
    "            all_ok = False\n",
    "\n",
    "        print(f\"  {cls}: {actual} images {status}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "# =========================\n",
    "# CHECK FOR DATA LEAKAGE\n",
    "# =========================\n",
    "print(\"ðŸ”Ž CHECKING FOR DATA LEAKAGE\\n\")\n",
    "\n",
    "for cls in CLASSES:\n",
    "    train = split_files[cls][\"train\"]\n",
    "    val   = split_files[cls][\"val\"]\n",
    "    test  = split_files[cls][\"test\"]\n",
    "\n",
    "    overlap_tv = train & val\n",
    "    overlap_tt = train & test\n",
    "    overlap_vt = val & test\n",
    "\n",
    "    if overlap_tv or overlap_tt or overlap_vt:\n",
    "        print(f\"âŒ Data leakage detected in {cls}\")\n",
    "        all_ok = False\n",
    "    else:\n",
    "        print(f\"âœ… No overlap in {cls}\")\n",
    "\n",
    "# =========================\n",
    "# FINAL RESULT\n",
    "# =========================\n",
    "print(\"\\n==============================\")\n",
    "if all_ok:\n",
    "    print(\"ðŸŽ‰ DATASET VERIFIED SUCCESSFULLY\")\n",
    "    print(\"âœ” Balanced\")\n",
    "    print(\"âœ” Correct splits\")\n",
    "    print(\"âœ” No leakage\")\n",
    "else:\n",
    "    print(\"âš ï¸ DATASET VERIFICATION FAILED\")\n",
    "    print(\"Check the errors above\")\n",
    "print(\"==============================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isic_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
